\documentclass[letterpaper,11pt]{article}

%packages
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage[left=2cm,top=2cm,right=2cm,bottom=2cm,head=.5cm,foot=.5cm]{geometry}
\usepackage{url}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{subfig}
\usepackage{float}
\usepackage{setspace}
\usepackage{lineno}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{xr}
%\usepackage{authblk}
%\usepackage{accents}

\DeclareRobustCommand{\bbone}{\text{\usefont{U}{bbold}{m}{n}1}}

\DeclareMathOperator{\EX}{E}% expected value
\DeclareMathOperator{\VarX}{var}
\DeclareMathOperator{\CovX}{cov}
\DeclareMathOperator{\mean}{mean}
\DeclareMathOperator{\se}{se}
\DeclareMathOperator{\sd}{sd}
\DeclareMathOperator{\Prob}{P}


%new commands and so on


%external documents
\externaldocument[MT-]{Paper}

%header material for paper
\title{Drivers of spatial synchrony in giant kelp populations}
\date{}

%***Tentative author order
\author{Lawrence W. Sheppard}
\author{Daniel C. Reuman}
\author{Tom Bell}
\author{Jonathan Walter}
\author{Kyle Cavanaugh}
\author{Max Castorani}

\usepackage{Sweave}
\begin{document}
\input{SupMat-concordance}

%The following is where you load in the numeric results that will be embedded in the text

\maketitle

%probably want table of contents, figure and table lists

\section{The Model}

We used the lottery model, previously studied, for instance, by REFS. Model equations are

\begin{equation}
N_i(t+1)=(1-\delta)N(t)+\delta N \frac{B_i(t)N_i(t)}{B_1(t)N_1(t)+B_2(t)N_2(t)}  \label{model_eq}
\end{equation}

\noindent for species $i=1,2$. 
Here, $N_i(t)$ is the population density of species $i$ at time $t$, and $N = N_1(t)+N_2(t)$ is fixed through time. 
The parameter, $\delta$ is a mortality rate, and $B_i(t)$ is the fecundiity of specise $i$ at time $t$. 
The model postulates that individuals die at rate $\delta$ at each time step, and are replaced by juveniles in population to the reproductive output of the two species that year.
We take, for each $i$, $B_i(t)$ to be $iid$ through time. 
We let $B_i = \exp(b_i)$, where $\left(b_1, b_2\right)$ is some distribution such that $b_i \sim N\left(\mu_i, \sigma^2\right)$ and such that $\CovX(b_1, b_2) = \rho$, a fixed quantity we will specify later.
However, $\left(b_1, b_2\right)$ is not necessarily a bivariate normal distribution.
We will consider various distributions of $\left(b_1, b_2\right)$ with these properties, corresponding to our symmetric and asymmetric tail associations cases defined in the main text and elaborated below.
We assume without loss of generality that $\mu_1 \leq \mu_2$, so that species 1 is the weaker competitor. 

\section{Noise} \label{sect:noise}

We created three cases for $(b_1,b_2)$, the case of symmetric tail association and the cases of asymmetrical left- and right-tail association. 
To generate $M$ points $\left(b_1^{(i)}, b_2^{(i)}\right)$, $i=1,..,M$, for the left tail association case, we first generated M points $(a_1^{(i)},a_2^{(i)})$, $i=1,...,M$, from a bivariate normal distribution $N\left( \vec{0}, \Sigma \right)$, where here $\Sigma = \begin{pmatrix} 1&0\\0&1\end{pmatrix}$. 
Then, for each index $i$, we randomly, with 50\% probability, either (A) let $\tilde b_1^{(i)} = -|a_1^{(i)}|$ and $\tilde b_2^{(i)} = -a|_1^{(i)}|$, or (B) let $\tilde b_1^{(i)} = |a_1^{(i)}|$ and $\tilde b_2^{(i)} = |a_2^{(i)}|$. 
We then let $b_1^{(i)} = \sigma \tilde b_1^{(i)} + \mu_1$ and $b_2^{(i)} = \sigma \tilde b_2^{(i)} + \mu_2$. 
Perfect association in the left tails of the resulting distribution $\left(b_1,b_2\right)$ results from the fact that, in case (A) above, both $\tilde b_1^{(i)}$ and $\tilde b_2^{(i)}$ were assigned to the same value. 
For speed of computation, when samples $(\tilde b_1^{(i)},\tilde b_2^{(i)})$, $i=1,...,M$ were needed for every distinct set of values of the parameters $\mu_1$, $\mu_2$, and $\sigma^2$, we used the same $\left(\tilde b_1^{(i)},\tilde b_2^{(i)}\right)$, $i=1,...,M$, simply transforming these values differently (using the different valus of $\mu_1$, $\mu_2$, $\sigma$) for each set of parameter values. Right-tail associated noise was generated in an analogous way. 

Noise with symmetric tail association was generated by taking a very large sample (100000) of left-tail associated noise, as described above, and then calculating the Pearson correaltion coefficient, rho.
The value obtained was ... . 
The symmetric noise was then generated once from $N\left(\vec{0}, \Sigma \right)$ where $\Sigma = \begin{pmatrix} 1&\rho \\ \rho&1\end{pmatrix}$, denoting the points so generated by $\left(\tilde b_1^{(i)},\tilde b_2^{(i)}\right)$ for $i=1,...,M$. 
We then set $b_1^{(i)} = \sigma \tilde b_1^{(i)} + \mu_1$ and $b_2^{(i)} = \sigma \tilde b_2^{(i)}+ \mu_2$.

Thus, overall, our model was completely specified by specifying $\delta$, $\mu_1$, $\mu_2$, $\sigma$ and whether noise was generated from the left-tailed association, right-tailed association or symmetric tail association cases specified above. 



\section{Invasion growth rate of species 1, and storage effects} \label{sect:IGR}

We consider the invasion growth rate of species 1, $\bar r_1=\EX(\ln (\frac{N_1(t+1)}{N_1(t)}))$, when $N_1$ is close to 0 and $N_2$ is close to $N$.
Hence $\EX(\cdot)$ represents expected value.
We have 

\begin{equation}
\frac{N_1(t+1)}{N_1(t)}=(1-\delta)+\delta N \frac{B_1(t)}{B_1(t)N_1(t)+B_2(t)N_2(t)},  \label{sp1_Nt+1_over_Nt}
\end{equation}

\noindent but setting $N_1=0$ and $N_2=N$ here gives the result that

\begin{equation}
\bar r_1=\EX(\ln [(1-\delta)+\delta \exp(b_1-b_2)]).  \label{rbar1_E}
\end{equation}

\noindent We considered the various cases for the joint distribution $(b_1,b_2)$, specified in the main text and in the previous section. 

To study storage effect for the model, we also consider the contribution of EC covariance to the difference between the invader's and the resident's mean growth rates, to be denoted $\Delta I$. 
Following REF, we define 

\begin{equation}
\bar r_1^\#=\EX(\ln [(1-\delta)+\delta \exp (b_1^\#-b_2)]),  \label{rbar1sharp_E}
\end{equation}

\noindent where $b_1^\#$ is distributed in the same way as $b_1$, but is independent of it and $b_2$. 
Then $\bar r_1 - \bar r_1^\#$ is the contribution of EC covariance to the mean growth rate species 1, the invader. 
We know, a priori, that the mean growth rate of the resident, species 2, must be 0, $\bar r_2 =0$, but equation (\ref{model_eq}) also implies that

\begin{equation}
\frac{N_2(t+1)}{N_2(t)}=(1-\delta)+\delta N \frac{B_2(t)}{B_1(t)N_1(t)+B_2(t)N_2(t)}.  \label{sp2_Nt+1_over_Nt}
\end{equation}

\noindent Setting $N_2=N$ and $N_1=0$ then gives

\begin{equation}
\frac{N_2(t+1)}{N_2(t)}=(1-\delta)+\delta=1  \label{sp2_Nt+1_over_Nt_simp}
\end{equation}

\noindent so

\begin{equation}
\EX(\ln (\frac{N_2(t+1)}{N_2(t)}))=0, \label{r2_is_zero}
\end{equation}

\noindent as expected. 
Again, following REF, we also define

\begin{equation}
\bar r_2^\#=\EX(\ln [(1-\delta)+\delta \exp(b_2^\#-b_2)]),  \label{rbar2sharp_E}
\end{equation}

\noindent where $b_2^\#$ is distributed in the same way as $b_2$, but is independent of it and of $b_1$. 
Thus $\bar r_2- \bar r_2^\# = -\bar r_2^\#$ is the contribution of EC covariance to the mean growth rate of species 2, the resident. 
And so

\begin{equation}
\Delta I=\left(\bar r_1 - \bar r_1^\#\right)-\left(\bar r_2- \bar r_2^\#\right)=\bar r_1 - \bar r_1^\#+\bar r_2^\#  \label{DeltaI}
\end{equation}

\noindent has been defined in terms of expected values of elementary expressions of the random variables $\left(b_1,b_2\right)$, $\left(b_1^\#,b_2\right)$, and $\left(b_2^\#, b_2\right)$.

Having already specified that $b_1$ (and therefore also $b_1^\#$) is distributed as $N\left(\mu_1, \sigma^2\right)$, and that $b_2$ (and therefore also $b_2^\#$) is distributed as $N\left(\mu_2, \sigma^2\right)$, we know, using $\Sigma$ as notation for a covariance matrix that

\begin{equation}
\left(b_1^\#, b_2\right) \sim N\left((\mu_1,\mu_2),\Sigma \right) \label{b1sharpb2_distribution}
\end{equation}

\noindent and 

\begin{equation}
\left(b_2^\#, b_2\right) \sim N(( \mu_2,\mu_2), \Sigma) \label{b2sharpb2_distribution}
\end{equation}

\noindent where

\begin{equation}
\Sigma = \begin{pmatrix} \sigma^2&0\\0&\sigma^2\end{pmatrix}. \label{Sigmamat_cov0}
\end{equation}

\noindent Thus the difference $b_1^\#-b_2$ that occurs in the expression for $\bar r_1^\#$ (\ref{rbar1sharp_E}) is a normally distributed random variable with mean $\mu_1-\mu_2$ and variance $2\sigma^2$. 
Thus

\begin{equation}
\bar r_1^\#=\EX(\ln [(1-\delta)+\delta \exp(u)]),  \label{rbar1sharp_E_usub}
\end{equation}

\noindent where $u \sim N(\mu_1-\mu_2,2\sigma^2)$. 
Likewise, the difference $b_2^\#-b_2$ in (\ref{rbar2sharp_E}) is a normally distributed random variable with mean $\mu_2-\mu_2=0$ and variance $2\sigma^2$, so

\begin{equation}
\bar r_2^\#=\EX(\ln [(1-\delta)+\delta \exp(u)]),  \label{rbar2sharp_E_usub}
\end{equation}

\noindent where now $u \sim N(0,2\sigma^2)$. 
The expression (\ref{rbar1_E}) for $\bar r_1$ can also be further simplified, in a similar way, when we are in the symmetric tail association case considered in section \ref{sect:noise}. 
In that case,

\begin{equation}
(b_1,b_2) \sim  N(( \mu_1,\mu_2), \Sigma) \label{b1b2_distribution_sym}
\end{equation}

\noindent where now

\begin{equation}
\Sigma = \begin{pmatrix} \sigma^2&\rho\\\rho&\sigma^2\end{pmatrix} \label{Sigmamat_rho}
\end{equation}

\noindent and $rho=put in value$ was determined as in section \ref{sect:noise}.
Therefore, the expression $b_1-b_2$ that occurred in \ref{rbar1_E}, in the symmetric tail association case, is a normally distributed random variable with mean $\mu_1-\mu_2$ and variance

\begin{align}
\VarX(b_1-b_2)&=\CovX(b_1-b_2, b_1-b_2) \\
                        &=\CovX(b_1,b_1)+\CovX(b_2,b_2)-\CovX(b_1,b_2)-\CovX(b_2,b_1) \\
                        &=2\sigma^2-2\rho.
\end{align}

\noindent Thus, again only in the symmetric tail association case,

\begin{equation}
\bar r_1 = \EX(\ln[1-\delta+\delta \exp(u)]), \label{rbar1_E_usub}
\end{equation}

\noindent where here $u \sim N(\mu_1-\mu_2, 2\sigma^2-2\rho)$. 
As for all we know there is no simplicifaction of the expression \ref{rbar1_E}  for $\bar r_1$ in the left and right-tail association cases. 

Thus for in summary,

\begin{equation}
\bar r_1 = \EX(\ln[1-\delta+\delta \exp(u)]), u \sim N(\mu_1-\mu_2, 2\sigma^2-2\rho), \label{sym_rbar1}
\end{equation}

\noindent for the symmetric case, and 

\begin{equation}
\bar r_1^{\#} = \EX(\ln[1-\delta+\delta \exp(u)]), u \sim N(\mu_1-\mu_2, 2\sigma^2), \label{sym_rbar1sharp}
\end{equation}

\begin{equation}
\bar r_2^{\#} = \EX(\ln[1-\delta+\delta \exp(u)]), u \sim N(0, 2\sigma^2). \label{sym_rbar2sharp}
\end{equation}

\noindent We next use the expressions to develop methods to estimate $\bar r_1$ and $\Delta I$ for any given paramters $\delta,\mu_1,\mu_2,\sigma$.




\section{Estimating $\bar r_1$ and $\Delta I$}

First, for a large integer $M$, carry out the following steps once:

\begin{enumerate}
\item Generate left-tail assocated noise $\left(\tilde b_{l1}^{(i)}, \tilde b_{l2}^{(i)}\right)$, $i=1,...,M$, as described in the section \ref{sect:noise}. Hence $\tilde b_{l1}^{i)}$ and $\tilde b_{l2}^{(i)}$ are distributed as $N(0,1)$. 
\item Generate right-tail associated noise $\left(\tilde b_{r1}^{(i)}, \tilde b_{r2}^{(i)}\right)$, $i=1,...,M$, via the analogous procedure. Again, $\tilde b_{r1}^{i)}$ and $\tilde b_{r2}^{(i)}$ are distributed as $N(0,1)$. 
\item Generate $M$ points $\tilde u_i$, $i = 1,...,M$ from a standard normal distribution. 
\end{enumerate}

\noindent Next, given values of parameters $\delta, \mu_1, \mu_2$, and $\sigma$, proceed as follows to get estimates of $\bar r_1, \bar r_1^{\#}, \bar r_2^{\#}$, and $\Delta I$. 

\begin{enumerate}

\item Estimate $\bar r_1$ for the left-tail associated case as $\hat \bar r_1 = \mean_i (\ln [1-\delta+\delta\exp(b_{l1}^{(i)}-b_{l2}^{(i)})])$ where $b_{l1}^{(i)} = \sigma \tilde b_{l1}^{(i)} + \mu_1$ and $b_{l2}^{(i)} = \sigma \tilde b_{l2}^{(i)} + \mu_2$. The standard error of this estimate is $\se (\hat \bar r_1) =\frac{\sd _i (\ln[1-\delta +\delta \exp(b_{l1}^{(i)}-b_{l2}^{(i)})])}{\sqrt M}$, where $\sd _i(\cdot)$ is standard deviation. 

\item Estiate $\bar r_1$ for the left-tail associated case as $\hat \bar r_1 = \mean_i (\ln [1-\delta+\delta\exp(b_{r1}^{(i)}-b_{r2}^{(i)})])$ where $b_{r1}^{(i)} = \sigma \tilde b_{r1}^{(i)} + \mu_1$ and $b_{r2}^{(i)} = \sigma \tilde b_{r2}^{(i)} + \mu_2$. The standard error of this estimate is $\se (\hat \bar r_1) =\frac{\sd _i (\ln[1-\delta +\delta \exp(b_{r1}^{(i)}-b_{r2}^{(i)})])}{\sqrt M}$. 

\item Estimate $\bar r_1$ in the symmetric tail association case as $\hat \bar r_1=\mean_i(\ln[1-\delta+\delta \exp(u_i)])$, where $u_i = \sqrt{(2\sigma^2-2\rho)}\tilde u_i + \mu_1 - \mu_2$. The standard error of this estimation is $\se(\hat \bar r_1) = \frac {\sd_i(\ln[1-\delta+\delta \exp(u_i)])}{\sqrt M}$. 

\item Estimate $\bar r_1^{\#}$ (for all three tail-assocaition cases) as $\hat \bar r_1^{\#} = \mean_i(\ln[1-\delta+\delta \exp(u_i)])$, where $u_i = \sqrt{2\sigma^2}\tilde u_i + \mu_1 - \mu_2$. The standard error is $\se(\hat \bar r_1^{\#}) = \sd_i \frac{ln[1-\delta+\delta \exp(u_i)]}{\sqrt M}$.    

\item Estimate $\bar r_2^{\#}$ (for all three tail-assocaition cases) as $\hat \bar r_2^{\#} = \mean_i(\ln[1-\delta+\delta \exp(u_i)])$, where $u_i = \sqrt{2\sigma^2}\tilde u_i$. The standard error is $\se(\hat \bar r_2^{\#}) = \sd_i \frac{ln[1-\delta+\delta \exp(u_i)]}{\sqrt M}$.    

\item $\hat {\Delta I} = \hat \bar r_1 - \hat \bar r_1^{\#} + \hat \bar r_2^{\#}$, estimated separately for the left-tail associated, right-tail associated and symmetric noise cases. We obtained conservative standard error estimates by adding the standard error of the estimates of $\hat \bar r_1, \hat \bar r_1^{\#}$, and $\hat \bar r_2^{\#}$.

\end{enumerate}

\noindent For large enough $M$, standard error should be very small. Since random variables are generated once only, computation of these quantitaties for a large number of parameter sets should be fast. 


\section{Additional quantities influencing invasion success} \label{sect:addquant}

Not only does the expected value $\bar r_1$ influence the capacity for species 1 to invade where rare, but so do other aspects of the distribution of
\begin{equation}
r_1 = \ln[1-\delta+\delta \exp(b_1-b_2)]. \label{r1_distribution}
\end{equation}

We here elaborate how some other aspects of the distribution of $r_1$ were quantified, for our three tail association cases and for any of our parameters $\delta, \mu_1, \mu_2, \sigma$. 

First, we considered $\sd(r_1)$, the standard deviation. If this is large enough, then $r_1$ can occasionally be positive even if $\bar r_1$ is strongly negative, and this invasion can occur under the right environmental circumstances.

We also considered the probability $\Prob[r_1 >0]$, which is, explicitly, the probability that environmental variables that permit invasion. We have
\begin{align}
\Prob[r_1>0] &= \Prob [1-\delta+\delta \exp(b_1-b_2) > 1] \\
&= \Prob[\exp (b_1-b_2)>1] \\
&= \Prob[b_1>b_2],
\end{align}

\noindent so this was computed for each considered parameter set of $\delta, \mu_1, \mu_2, \sigma$, and for each of our three tail association cases. 

We also consider the mean value of the possible part of the distribution of $r_1$, $\EX(r_1|r_1>0)$. 
This characterizes how quickly invasion may happen, when it happens, with larger values corresponding to faster invasion. 
If it takes several time steps for the population of the invader to rise from negligible level at which species 1 is a noticeable presence in the community, then environmental conditions must be suitable for invasion for several sequential time steps. 
Thus large values of $\EX(r_1|r_1>0)$ should also correspond to a greater probability of invasion because they should correspond to faster invasions and therefore to reduced need for sequential periods of suitable environmental conditions. 

Finally, for a few choices of parameters $\delta, \mu_1, \mu_2, \sigma$, we displayed the whole distribution of $r_1$, values for each of our tail association cases, to make visual comparisons. 

\section{Symmetries and parameter reduction}

The quantities we consider to address invasion prospects for the weaker competitor, species 1 (see sections \ref{sect:IGR} and \ref{sect:addquant}) depend only on $\mu_1-\mu_2$ and not, independtly, on $\mu_1$ and $\mu_2$, and also are the same for our left- and right-tailed association cases. We prove these statements in this section.

Equations \ref{sym_rbar1} - \ref{sym_rbar2sharp} obviously depend only on $\mu_1-\mu_2$, and not independently on $\mu_1$ and $\mu_2$, since only $\mu_1-\mu_2$ appears in these expressions if $\mu_1$ or $\mu_2$ appear at all. 
Equation \ref{rbar1_E} is $\bar r_1$ in the asymmetric tail association cases.
But letting $\beta_1 = b_1 + \eta$ and $\beta_2 = b_2 + \eta$ and substituting into \ref{rbar1_E}, we get 

\begin{align}
\bar r_1 &= \EX(\ln[1-\delta+\delta \exp(\beta_1-\eta-(\beta_2-\eta))])\\
&= \EX(\ln[1-\delta+\delta \exp(\beta_1-\beta_2)]).
\end{align}
\noindent And so altering the mean of both $b_1$ and $b_2$ distributions by the same amount has no affect of $\bar r_1$, and thus $\bar r_1$ in the asymmetric tail associations also depends only on $\mu_1 - \mu_2$ and not independtly on $\mu_1$ or $\mu_2$.

In section \ref{sect:addquant}, we introduce several other metrics. These are all based on the distribution 
\begin{equation}
r_1=\ln[1-\delta+\delta \exp(b_1-b_2)]. \label{r1distribution}
\end{equation}

\noindent But, again making the substitutions $\beta_1 = b_1 + \eta$ and $\beta_2 = b_2 + \eta$, we can see via the same resoning as above that the whole distribution $r_1$ depends only on $\mu_1 - \mu_2$, and not on $\mu_1$ and $\mu_2$ independently, for all three of our tail association cases.

To see that our various metrics are the same for out left- and right-tail associated noise processes, let $(b_1,b_2)$ denote our left-tail associated random variable with parameters $\mu_1,\mu_2,\sigma$. 
Then define $\beta_1 = -b_2 + \mu_1 +\mu_2$, $\beta_2=-b_1+\mu_1+\mu_2$. 
It is easy to see that $\EX(\beta_1)=\mu_1$, $\EX(\beta_2)=\mu_2$, $\sd(\beta_1)=\sd(\beta_2)=\sigma$, so $\beta_1$ and $\beta_2$ are normally distributed.
From there it is easy to see that $\beta_1$ and $beta_2$ are distributed in the same wat as our right-tail associated noise with parameter $\mu_1,\mu_2$, and $\sigma$. 
Making the substitutions $b_2 = -\beta_1 + \mu_1 + \mu_2$ and $b_1 = -\beta_2 + \mu_1+\mu_2$ in \ref{r1distribution}, we get

\begin{align}
r_1 &= \ln[1-\delta+\delta \exp(-\beta_2+\mu_1+\mu_2-(\beta_1+\mu_1+\mu_2))]\\
&= \ln[1-\delta+\delta \exp(\beta_1-\beta_2)].
\end{align}

\noindent And since $(\beta_1, \beta_2)$ is distributed in the same way as our right-tail associated noise, this proves all metrics based on the distribution of $r_1$ (\ref{r1distribution}) are the same for left- and right-tail associated noise.



\section{New Stuff}

Fixed number, base growth rate

\begin{equation}
\epsilon_i^0=\ln(1-\delta + \delta \frac{\bar B_i}{\bar B_j}) \label{null_i}
\end{equation}

\begin{equation}
\epsilon_i^E=\ln(1-\delta + \delta \frac{B_i}{\bar B_j}) -  \epsilon_i^0 \label{Evar}
\end{equation}

contribution of variance in E

\begin{equation}
\bar \epsilon_i^E=\EX(\epsilon_i^E) \label{Evar_mean}
\end{equation}

\begin{equation}
\epsilon_i^C=\ln(1-\delta + \delta \frac{\bar B_i}{B_j}) -  \epsilon_i^0 \label{Cvar}
\end{equation}

contribution of variance in C

\begin{equation}
\bar \epsilon_i^C=\EX(\epsilon_i^C) \label{Cvar_mean}
\end{equation}

\begin{equation}
\epsilon_i^{EC}=\ln(1-\delta + \delta \frac{B_i}{B_j}) -  [\epsilon_i^0 + \epsilon_i^E + \epsilon_i^C] \label{ECvar}
\end{equation}

interaction effect of both E and C varying

\begin{equation}
\bar \epsilon_i^{EC}=\EX(\ln(1-\delta + \delta \frac{B_i}{B_j})) -[\epsilon_i^0 +\bar \epsilon_i^E + \bar \epsilon_i^C] \label{ECvar_mean}
\end{equation}

\begin{equation}
\bar r_i=\EX(\ln(1-\delta + \delta \frac{B_i}{B_j}))\label{rbari}
\end{equation}

\begin{equation}
\bar r_i=\epsilon_i^0 +\bar \epsilon_i^E + \bar \epsilon_i^C + \bar \epsilon_i^{EC} \label{rbari_decomp}
\end{equation}

But some of $\bar \epsilon_i^{EC}$ comes from covariance between E and C and some comes from both varying.

\begin{equation}
\bar \epsilon_i^{(E\#C)}=\EX(\ln(1-\delta + \delta \frac{B_i}{B_j^{\#}})) -[\epsilon_i^0 +\bar \epsilon_i^E + \bar \epsilon_i^C] \label{ECvar_sharp}
\end{equation}

\begin{align}
\bar \epsilon_i^{(EC)}&=\bar \epsilon_i^{EC}-\bar \epsilon_i^{(E\#C)}\\
&= \EX(\ln(1-\delta + \delta \frac{B_i}{B_j}))-[\epsilon_i^0 +\bar \epsilon_i^E + \bar \epsilon_i^C]\\
&- \EX(\ln(1-\delta + \delta \frac{B_i}{B_j^{\#}})) +[\epsilon_i^0 +\bar \epsilon_i^E + \bar \epsilon_i^C]
\label{r_iSE}
\end{align}

checks out






\end{document}
